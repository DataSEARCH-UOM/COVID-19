{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install requests lxml pandas --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_names = ['SRI LANKA','CHINA 1','CHINA 2','CHINA - HONG KONG','CHINA - MACAO','SPAIN','SPAIN - CANARY ISLAND','SPAIN - CEUTA AND MELILLA',\n",
    "#                 'FRANCE 1','GERMANY','INDIA','INDIA - NORTH','INDIA - SOUTH','ITALY','JAPAN','SPAIN- JUAN CARLOS','USA 1','USA 2','THAILAND',\n",
    "#                 'AUSTRALIA 1','AUSTRALIA 2','AUSTRALIA 3','AUSTRALIA 4','AUSTRALIA 5','AUSTRALIA 6','AUSTRALIA 7','AUSTRALIA 8',\n",
    "#                 'AUSTRIA', 'FRANCE 2', 'FRENCH GUIANA','FRENCH POLYNESIA 1','FRENCH POLYNESIA 2','FRENCH POLYNESIA 3','FRENCH POLYNESIA 4']\n",
    "# country_codes =  [2120, 7100,2250,2150,2160, 6140,1010,1024,7130,7030,7108,2100,2110,7134,7110,7102,7040,7042,2210,5320,5250,5260,\n",
    "#                  5270,5280,5290,5300,5310,6180,6130,3050,5210,5170,5190,5200]\n",
    "\n",
    "scrape_period = {'01' : ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30','31'],\n",
    "                 '02' : ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29'],\n",
    "                 '03' : ['01','02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']\n",
    "                }\n",
    "country_code_dict = {'SRI LANKA': 2120, 'CHINA 1': 7100, 'CHINA 2': 2250, 'CHINA - HONG KONG': 2150,\n",
    "                     'CHINA - MACAO': 2160,'SPAIN': 6140,'SPAIN - CANARY ISLAND': 1010,'SPAIN - CEUTA AND MELILLA': 1024,\n",
    "                     'FRANCE 1': 7130,'GERMANY': 7030,'INDIA': 7108,'INDIA - NORTH': 2100,'INDIA - SOUTH': 2110,\n",
    "                     'ITALY': 7134,'JAPAN': 7110,'SPAIN- JUAN CARLOS': 7102,'USA 1': 7040,'USA 2': 7042,'THAILAND': 2210,\n",
    "                     'AUSTRALIA 1': 5320,'AUSTRALIA 2': 5250,'AUSTRALIA 3': 5260,'AUSTRALIA 4': 5270,\n",
    "                     'AUSTRALIA 5': 5280,'AUSTRALIA 6': 5290,'AUSTRALIA 7': 5300,'AUSTRALIA 8': 5310,'AUSTRIA': 6180,\n",
    "                     'FRANCE 2': 6130,'FRENCH GUIANA': 3050,'FRENCH POLYNESIA 1': 5210,'FRENCH POLYNESIA 2': 5170,\n",
    "                     'FRENCH POLYNESIA 3': 5190,'FRENCH POLYNESIA 4': 5200\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(country_code, start_date, start_month, start_year, end_day, end_month,end_year):\n",
    "    url=\"http://www.meteomanz.com/sy2?l=1&cou=\"+str(country_code) + \"&ind=00000&d1=\" +str(start_day) + \"&m1=\" + start_month + \"&y1=\"+ str(start_year)+'&d2='+str(end_day) + '&m2=' + str(end_month) +'&y2='+ str(end_year) \n",
    "    print(url)\n",
    "    #Create a handle, page, to handle the contents of the website\n",
    "    page = requests.get(url)\n",
    "    #Store the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "    #Parse data that are stored between <tr>..</tr> of HTML\n",
    "    tr_elements = doc.xpath('//tr')\n",
    "    #Create empty list\n",
    "    col=[]\n",
    "    i=0#For each row, store each first element (header) and an empty list\n",
    "    for t in tr_elements[0]:\n",
    "        i+=1\n",
    "        name=t.text_content()\n",
    "#         print('%d:\"%s\"'%(i,name))\n",
    "        col.append((name,[]))\n",
    "    #Since out first row is the header, data is stored on the second row onwards\n",
    "    for j in range(1,len(tr_elements)):\n",
    "        #T is our j'th row\n",
    "        T=tr_elements[j]\n",
    "\n",
    "        #If row is not of size 10, the //tr data is not from our table \n",
    "        if len(T)!=10:\n",
    "            break\n",
    "\n",
    "        #i is the index of our column\n",
    "        i=0\n",
    "\n",
    "        #Iterate through each element of the row\n",
    "        for t in T.iterchildren():\n",
    "            data=t.text_content() \n",
    "            #Check if row is empty\n",
    "            if i>0:\n",
    "            #Convert any numerical value to integers\n",
    "                try:\n",
    "                    data=int(data)\n",
    "                except:\n",
    "                    pass\n",
    "            #Append the data to the empty list of the i'th column\n",
    "            col[i][1].append(data)\n",
    "            #Increment i for the next column\n",
    "            i+=1\n",
    "    Dict={title:column for (title,column) in col}\n",
    "    df=pd.DataFrame(Dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2020\n",
    "end_year = 2020\n",
    "all_countries_data= []\n",
    "for country_name in country_code_dict:\n",
    "    country_code = country_code_dict[country_name]\n",
    "    country_df = []\n",
    "    for month in scrape_period:\n",
    "        start_month = month\n",
    "        end_month = month\n",
    "        for day in scrape_period[month]:\n",
    "            start_day = day\n",
    "            end_day = day\n",
    "            day_df = scrape_page(country_code, start_day, start_month, start_year, end_day, end_month,end_year)\n",
    "            country_df.append(day_df)\n",
    "#         print(country_df)\n",
    "    country_df = pd.concat(country_df,ignore_index=True)\n",
    "    country_df['country'] = country_name\n",
    "    all_countries_data.append(country_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_data = pd.concat(all_countries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries_data.to_csv(\"daily_weather_data_selected_countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
